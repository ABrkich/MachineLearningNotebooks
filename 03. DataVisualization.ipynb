{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Manipulation in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here let's look at a different dataset that will allow us to really dive into some meaningful visualizations. This data set is publically available, but it is also part of a Kaggle competition.\n",
    "\n",
    "You can get the data from here: https://www.kaggle.com/c/titanic-gettingStarted or you can use the code below to load the data from GitHub.\n",
    "\n",
    "There are lots of iPython notebooks for looking at the Titanic data. Check them out and see if you like any better than this one!\n",
    "\n",
    "When going through visualization options, I recommend the following steps:\n",
    "- Would you like the visual to be interactive?\n",
    "  - Yes, Does it have a lot of data?\n",
    "    - No, Use plotly or bokeh\n",
    "    - Yes, sub-sample and then use plotly/bokeh\n",
    "    - Yes, think about using Turi for large data\n",
    "  - No, Does seaborn have a built-in function for plotting?\n",
    "    - Yes, use seaborn\n",
    "    - No, Does Pandas support the visual?\n",
    "      - Yes, use pandas\n",
    "      - No, use low level matplotlib\n",
    "      \n",
    "Look at various high level plotting libraries like:\n",
    "- Altair (https://altair-viz.github.io)\n",
    "- Bokeh (http://bokeh.pydata.org/en/latest/)\n",
    "- And many others...\n",
    "\n",
    "## Adding Dependencies (for Jupyter Lab)\n",
    "- `conda install -c conda-forge missingno`\n",
    "- `conda install nodejs`\n",
    "- `jupyter labextension install @jupyterlab/plotly-extension`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Titanic Data for Example Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Titanic dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print('Pandas:', pd.__version__)\n",
    "print('Numpy:',np.__version__)\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/eclarson/DataMiningNotebooks/master/data/titanic.csv') # read in the csv file\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the describe function defaults to using only some variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n",
    "print('===========')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions we might want to ask:\n",
    "- What percentage of passengers survived the Titanic disaster?\n",
    "- What percentage survived in each class (first, coach, etc.)?\n",
    "- How many people traveled in each class? How many classes are there?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the percentage of individuals that survived on the titanic\n",
    "sum(df.Survived==1)/len(df)*100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets aggregate by class and count survival rates\n",
    "df_grouped = df.groupby(by='Pclass')\n",
    "for val,grp in df_grouped:\n",
    "    print('There were',len(grp),'people traveling in',val,'class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of using the groupby function with a data column\n",
    "print(df_grouped['Survived'].sum())\n",
    "print('---------------------------------------')\n",
    "print(df_grouped.Survived.count())\n",
    "print('---------------------------------------')\n",
    "print(df_grouped.Survived.sum() / df_grouped.Survived.count())\n",
    "\n",
    "# might there be a better way of displaying this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Exercise üìù: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Exercise: Create code for calculating the std error\n",
    "# std / sqrt(N) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "# Cleaning the Dataset\n",
    "Let's start by visualizing some of the missing data in this dataset. We will use the `missingno` package to help visualize where the data contains `NaNs`. This is a great tool for looking at nan values and how we might go about filling in the values. \n",
    "\n",
    "For this visualization, we can use a visualization library called `missingno` that hs many types of visuals for looking at missing data in a dataframe. I particularly like the `matrix` visualization, but there are many more to explore:\n",
    "- https://github.com/ResidentMario/missingno\n",
    "\n",
    "### Plot Type One: Filter Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this python magics will allow plot to be embedded into the notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "\n",
    "import missingno as mn\n",
    "\n",
    "mn.matrix(df.sort_values(by=[\"Cabin\",\"Embarked\",\"Age\",]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's clean the dataset a little before moving on\n",
    "\n",
    "# 1. Remove attributes that just arent useful for us\n",
    "for col in ['PassengerId','Name','Cabin','Ticket']:\n",
    "    if col in df:\n",
    "        del df[col]\n",
    "        \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation Techniques \n",
    "Let's compare two different techniques from lecture on how to fill in missing data. Recall that imputation should be done with a great deal of caution. Here, the Age variable seems to be missing about 15% of the values. That might be too many to impute. Let's try two methods of imputation on the Age variable: \n",
    "- Split-Imput-Combine\n",
    "- Nearest Neighbor Imputation \n",
    "\n",
    "### Split-Impute-Combine in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for split, impute, combine\n",
    "#     those interested in , \n",
    "#     let's clean the dataset a little before moving on\n",
    "\n",
    "\n",
    "# Impute some missing values, grouped by their Pclass and SibSp numbers, \n",
    "# then use this grouping to fill the data set in each group, then transform back\n",
    "\n",
    "\n",
    "df_grouped = df.groupby(by=['Pclass','SibSp','Parch']) # perform the grouping of thing related to 'age'\n",
    "func = lambda grp: grp.fillna(grp.median()) # within groups, fill using median (define function to do this)\n",
    "df_imputed_sac = df_grouped.transform(func) # apply impute and transform the data back\n",
    "\n",
    "# Extra step: fill any deleted columns from the operation\n",
    "col_deleted = list( set(df.columns) - set(df_imputed_sac.columns)) # in case the median operation deleted columns\n",
    "df_imputed_sac[col_deleted] = df[col_deleted]\n",
    "\n",
    "# drop any rows that still had missing values after grouped imputation\n",
    "df_imputed_sac.dropna(inplace=True)\n",
    "\n",
    "# 5. Rearrange the columns\n",
    "df_imputed_sac = df_imputed_sac[['Survived','Age','Sex','Parch','SibSp','Pclass','Fare','Embarked']]\n",
    "df_imputed_sac.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor Imputation with Scikit-learn\n",
    "Now let's try to fill in the Age variable by selecting the 3 nearest data points to the given observation. Here, we can use additional variables in the distance calculation, as compared to the need for discrete variable in the split-impute-combine method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute based upon the K closest samples (rows)\n",
    "# our first introduction to sklearn!!!\n",
    "from sklearn.impute import KNNImputer\n",
    "import copy\n",
    "\n",
    "# get object for imputation\n",
    "knn_obj = KNNImputer(n_neighbors=3)\n",
    "\n",
    "features_to_use = ['Pclass','Age','SibSp','Parch','Fare']\n",
    "\n",
    "# create a numpy matrix from pandas numeric values to impute\n",
    "temp = df[features_to_use].to_numpy()\n",
    "\n",
    "# use sklearn imputation object\n",
    "knn_obj.fit(temp)\n",
    "temp_imputed = knn_obj.transform(temp)\n",
    "#    could have also done:\n",
    "# temp_imputed = knn_obj.fit_transform(temp)\n",
    "\n",
    "# this is VERY IMPORTANT, make a deep copy, not just a reference to the object\n",
    "# otherwise both data frames will be manipulated\n",
    "df_imputed = copy.deepcopy(df) # not just an alias\n",
    "df_imputed[features_to_use] = temp_imputed\n",
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties of the imputer after fitting\n",
    "print(knn_obj.n_features_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Imputation Distributions \n",
    "Now let's see whihc imputation method changed the overall histogram the least. Do you see anything in the plots below that would give preference in one method over another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's show some very basic plotting to be sure the data looks about the same\n",
    "# Which imputation did better? The PSlit-Apply-Combine, or  nearest Neighbor Imputer? \n",
    "df_imputed_sac.Age.plot(kind='hist', alpha=0.25, label=\"Split-Apply-Combine\")\n",
    "df_imputed.Age.plot(kind='hist', alpha=0.25, label=\"KNN-Imputer\")\n",
    "df.Age.plot(kind='hist', alpha=0.5, label=\"Original\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "**[back to slides]**\n",
    "\n",
    "# Feature Discretization\n",
    "This is an example of how to make a continuous feature and ordinal feature. Let's try to give some human intuition to a variable by grouping the data by age. \n",
    "\n",
    "**Question: Does age range influence survival rates?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's break up the age variable\n",
    "df_imputed['age_range'] = pd.cut(df_imputed['Age'],[0,15,25,65,1e6],\n",
    "                                 labels=['child','young adult','adult','senior']) # this creates a new variable\n",
    "df_imputed.age_range.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets group with the new variable\n",
    "df_grouped = df_imputed.groupby(by=['Pclass','age_range'])\n",
    "print (\"Percentage of survivors in each group:\")\n",
    "print (df_grouped.Survived.sum() / df_grouped.Survived.count() *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__________\n",
    "___________\n",
    "# Visualization in Python with Pandas, Matplotlib, and Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this python magics will allow plot to be embedded into the notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "\n",
    "print('Matplotlib:', matplotlib. __version__)\n",
    "# could also say \"%matplotlib notebook\" here to make things interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "## Visualizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has plenty of plotting abilities built in. Let's take a look at a few of the different graphing capabilities of Pandas with only matplotlib. Afterward, we can make the visualizations more beautiful.\n",
    "\n",
    "### Visualization Techniques: Distributions\n",
    "- Histogram \n",
    " - Usually shows the distribution of values of a single variable\n",
    " - Divide the values into bins and show a bar plot of the number of objects in each bin. \n",
    "- Kernel Density Estimation\n",
    " - Add up Gaussian underneath each point value\n",
    " - STD of gaussian is visually related to \"number of bins\" for a histogram\n",
    " \n",
    " **KDE Example:** \n",
    " <img src=\"PDF_slides/kernels.gif\" alt=\"TukeyBoxplot\" width=\"600\" height=\"600\">\n",
    " \n",
    " ___\n",
    " \n",
    " \n",
    " #### Plot Type Two: Histogram and Kernel Density\n",
    " \n",
    " **Question: What were the ages of people on the Titanic?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by just plotting what we previously grouped!\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "df_imputed.Age.plot.hist(bins=20)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "df_imputed.Age.plot.kde(bw_method=0.2)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "df_imputed.Age.plot.hist(bins=50)\n",
    "df_imputed.Age.plot.kde(bw_method=0.05, secondary_y=True)\n",
    "\n",
    "# remember that visualization is interpretted, it supports evidence.\n",
    "# plt.ylim([0, 0.06])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-Dimensional Distributions\n",
    "- Estimate the joint distribution of the values of two attributes \n",
    " - Example: petal width and petal length\n",
    "  - What does this tell us? \n",
    "  \n",
    " **Question: How does age relate to the fare that was paid?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x=df_imputed.Age, y=df_imputed.Fare, bins=30)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Fare\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot is not all that meaningful. We can probably do better than visualizing the joint distribution using 2D histograms. Let's face it: 2D histrogram are bound to be sparse and not very descriptive. Instead, let's do something smarter.\n",
    "\n",
    "## Feature Correlation Plot\n",
    " - First lets visualize the correlation between the different features.\n",
    " \n",
    "  #### Plot Type Three: Heatmap (of correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation matrix \n",
    "vars_to_use = ['Survived', 'Age', 'Parch', 'SibSp', 'Pclass', 'Fare'] # pick vars\n",
    "plt.pcolor(df_imputed[vars_to_use].corr()) # do the feature correlation plot\n",
    "\n",
    "# fill in the indices\n",
    "plt.yticks(np.arange(0.5, len(vars_to_use), 1), vars_to_use)\n",
    "plt.xticks(np.arange(0.5, len(vars_to_use), 1), vars_to_use)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped Count Plots\n",
    "Used when you have multiple categorical or nominal variables that you want to show together in sub-groups. Grouping mean to display the counts of different subgroups on the dataset. For the titanic data, this can be quite telling of the dataset.\n",
    "\n",
    "**Question: Does age, gender, or class have an effect on survival?**\n",
    "\n",
    " #### Plot Type Four: Grouped Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first group the data\n",
    "df_grouped = df_imputed.groupby(by=['Pclass','age_range'])\n",
    "\n",
    "# tabulate survival rates of each group\n",
    "survival_rate = df_grouped.Survived.sum() / df_grouped.Survived.count()\n",
    "\n",
    "# show in a bar chart using builtin pandas API\n",
    "ax = survival_rate.plot(kind='barh')\n",
    "plt.title('Survival Percentages by Class and Age Range')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cross tab operator provides an easy way to get these numbers\n",
    "survival = pd.crosstab([df_imputed['Pclass'],\n",
    "                        df_imputed['age_range']], # categories to cross tabulate\n",
    "                       df_imputed.Survived.astype(bool)) # how to group\n",
    "print(survival)\n",
    "\n",
    "survival.plot(kind='bar', stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overall cross tab with both groups\n",
    "plt.figure(figsize=(15,3))\n",
    "ax1 = plt.subplot(1,3,1)\n",
    "ax2 = plt.subplot(1,3,2)\n",
    "ax3 = plt.subplot(1,3,3)\n",
    "\n",
    "pd.crosstab([df_imputed['Pclass']], # categories to cross tabulate\n",
    "            df_imputed.Survived.astype(bool)).plot(kind='bar', stacked=True, ax=ax1) \n",
    "\n",
    "pd.crosstab([df_imputed['age_range']], # categories to cross tabulate\n",
    "            df_imputed.Survived.astype(bool)).plot(kind='bar', stacked=True, ax=ax2) \n",
    "\n",
    "pd.crosstab([df_imputed['Sex']], # categories to cross tabulate\n",
    "            df_imputed.Survived.astype(bool)).plot(kind='bar', stacked=True, ax=ax3) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-group Distribution Plots\n",
    "- Box Plots \n",
    " - Invented by J. Tukey\n",
    " - Another way of displaying the distribution of data \n",
    " - Following figure shows the basic part of a box plot:\n",
    " \n",
    "<img src=\"data/TukeyPlot.png\" alt=\"TukeyBoxplot\" width=\"600\" height=\"600\">\n",
    "\n",
    " #### Plot Type Five: Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_imputed.boxplot(column='Fare', by = 'Pclass') # group by class\n",
    "plt.ylabel('Fare')\n",
    "plt.title('')\n",
    "ax.set_yscale('log') # so that the boxplots are not squished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with boxplots is that they might hide important aspects of the ditribution. For example, this plot shows data that all have the exact same boxplot.\n",
    "\n",
    "<img src=\"https://i.redd.it/cad7mdrg9wez.gif\" alt=\"TukeyBoxplot\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplifying Plotting with Seaborn\n",
    "\n",
    "\n",
    "Using pandas and matplotlib is great until you need to redo or make more intricate plots. Let's see about one or two APIs that might simplify our lives. First, let's use Seaborn.\n",
    "+ `import seaborn as sns` \n",
    "\n",
    "In seaborn, we have access to a number of different plotting tools. Let's take a look at:\n",
    " #### Plot Type Six:\n",
    "- Box Plots\n",
    "- Swarm Plots\n",
    "- Violin Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# cmap = sns.diverging_palette(220, 10, as_cmap=True) # one of the many color mappings\n",
    "\n",
    "print('Seaborn:', sns. __version__)\n",
    "# now try plotting some of the previous plots, way more visually appealing!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns boxplot\n",
    "plt.subplots(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(x=\"Sex\", y=\"Age\", hue=\"Survived\", data=df_imputed)\n",
    "plt.title('Boxplot Example')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.violinplot(x=\"Sex\", y=\"Age\", hue=\"Survived\", data=df_imputed)\n",
    "plt.title('Violin Example')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.swarmplot(x=\"Sex\", y=\"Age\", hue=\"Survived\", data=df_imputed)\n",
    "plt.title('Swarm Example')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASIDE: UGH so much repeated code, can we do \"better\"?\n",
    "# this use slick python functionality as the cost of readability\n",
    "plt.subplots(figsize=(20, 5))\n",
    "args = {'x':\"Sex\", 'y':\"Age\", 'hue':\"Survived\", 'data':df_imputed}\n",
    "for i, plot_func in enumerate([sns.boxplot, sns.violinplot, sns.swarmplot]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plot_func(**args) # more compact, LESS readable\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"Sex\", y=\"Age\", hue=\"Survived\", data=df_imputed, \n",
    "               split=True, # split across violins\n",
    "               inner=\"quart\", # show innner stats like mena, IQR, \n",
    "               scale=\"count\") # scale the size of the plot by the count within each group\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "\n",
    "\n",
    "### Self Test 2a.2\n",
    "<img src=\"data/self_test_2a_2.png\" alt=\"TukeyBoxplot\" width=\"600\" height=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Matrix Plots\n",
    "- Plot some data from a matrix\n",
    "- This can be useful when objects are sorted well\n",
    "- Typically, the attributes are normalized to prevent one attribute from dominating the plot\n",
    "- Plots of similarity or distance matrices can also be useful for visualizing the relationships between objects\n",
    "- Two versions:\n",
    " - Feature Based\n",
    " - Instance Based\n",
    " \n",
    " **Question: Which features are most similar to each other?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the correlation plot is Feature based becasue we get\n",
    "# a place in the plot for each feature\n",
    "# in this plot we are asking, what features are most correlated? \n",
    "cmap = sns.set(style=\"darkgrid\") # one of the many styles to plot using\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(df_imputed.corr(), cmap=cmap, annot=True)\n",
    "\n",
    "# f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "____\n",
    "\n",
    "**New Question: Which passengers are most similar to one another?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but we could also be asking, what instances are most similar to each other?\n",
    "\n",
    "# NOTE: Correlation here is defined as a distance metric by scipy \n",
    "# https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.correlation.html \n",
    "# it is defined as 1-CC, so '0' means highly correlated\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "vars_to_use = [ 'Age', 'Pclass', 'Fare', 'SibSp','Parch'] # pick vars\n",
    "\n",
    "xdata = pairwise_distances(df_imputed[vars_to_use].values, # get numpy matrix\n",
    "                           metric='correlation')\n",
    "sns.heatmap(xdata, cmap=cmap, annot=False)\n",
    "print('What is wrong with this plot?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets fix a few things\n",
    "# first, the difference between each instance was large, \n",
    "#  impacted by the biggest variable, Fare\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# lets scale the data to be zero mean, unit variance\n",
    "std = StandardScaler()\n",
    "\n",
    "xdata = pairwise_distances(std.fit_transform(df_imputed[vars_to_use].to_numpy()), \n",
    "                           metric='correlation')\n",
    "sns.heatmap(xdata, cmap=cmap, annot=False)\n",
    "print('Is there still something wrong?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "# lets scale the data to be zero mean, unit variance\n",
    "std = StandardScaler()\n",
    "# and lets also sort the data\n",
    "df_imputed_copy = df_imputed.copy().sort_values(by=['Pclass','Age','Survived'])\n",
    "\n",
    "xdata = pairwise_distances(std.fit_transform(df_imputed_copy[vars_to_use].values), \n",
    "                           metric='correlation')\n",
    "sns.heatmap(xdata, cmap=cmap, annot=False)\n",
    "print('Is there anything we can conclude?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "## Revisiting other Plots in Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we make a better combined histogram and KDE?\n",
    "sns.distplot(df_imputed.Age)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make a pretty plot of the scatter matrix\n",
    "df_imputed_jitter = df_imputed.copy()\n",
    "df_imputed_jitter[['Parch','SibSp','Pclass']] += np.random.rand(len(df_imputed_jitter),3)/2 \n",
    "sns.pairplot(df_imputed_jitter, hue=\"Survived\", size=2,\n",
    "            plot_kws=dict(s=20, alpha=0.15, linewidth=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Final Note on Plotting:\n",
    "The best plots that you can make are probably ones that are completely custom to the task or question you are trying to solve/answer. These plots are also the most difficult to get correct because they take a great deal of iteration, time, and effort to get perfected. They also take some time to explain. There is a delicate balance between creating a new plot that answers exactly what you are asking (in the best way possible) and spending and inordinate amount of time on a new plot (when a standard plot might be a \"pretty good\" answer)\n",
    "\n",
    "<img src=\"PDF_slides/Customplots.png\" alt=\"TukeyBoxplot\" width=\"600\" height=\"600\">\n",
    "\n",
    "\n",
    "____\n",
    "# Revisiting with Interactive Visuals: Plotly\n",
    "- https://plot.ly/python/getting-started/\n",
    "\n",
    "More updates to come to this section of the notebook. Plotly is a major step in the direction of using JavaScript and python together and I would argue it has a much better implementation than other packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly from the getting started example...\n",
    "import plotly\n",
    "print('Plotly:', plotly. __version__)\n",
    "\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "plotly.offline.iplot({\n",
    "    \"data\": [{\n",
    "        \"x\": [1, 2, 3],\n",
    "        \"y\": [4, 2, 5]\n",
    "    }],\n",
    "    \"layout\": {\n",
    "        \"title\": \"hello world\"\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.graph_objs import Scatter, Layout\n",
    "from plotly.graph_objs.scatter import Marker\n",
    "from plotly.graph_objs.layout import XAxis, YAxis\n",
    "# let's manipulate the example to serve our purposes\n",
    "\n",
    "# plotly allows us to create JS graph elements, like a scatter object\n",
    "plotly.offline.iplot({\n",
    "    'data':[\n",
    "        Scatter(x=df_imputed.SibSp.values+np.random.rand(*df_imputed.SibSp.shape)/2,\n",
    "                y=df_imputed.Age,\n",
    "      \n",
    "                text=df_imputed.Survived.values.astype(str),\n",
    "                marker=Marker(size=df_imputed.Fare, sizemode='area', sizeref=1,),\n",
    "                mode='markers')\n",
    "            ],\n",
    "    'layout': Layout(xaxis=XAxis(title='Sibling and Spouses'), \n",
    "                     yaxis=YAxis(title='Age'),\n",
    "                     title='Age and Family Size (Marker Size==Fare)')\n",
    "}, show_link=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing more than three attributes requires a good deal of thought. In the following graph, lets use interactivity to help bolster the analysis. We will create a graph with custom text overlays that help refine the passenger we are looking at. We will \n",
    "- color code whether they survived\n",
    "- Scatter plot Age and Social class\n",
    "- Code the number of siblings/spouses traveling with them through the size of the marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_text(df_row):\n",
    "    return 'Age: %d<br>Gender: %s<br>Class: %d<br>Fare: %.2f<br>SibSpouse: %d<br>ParChildren: %d'%(df_row.Age,df_row.Sex,df_row.Pclass,df_row.Fare,df_row.SibSp,df_row.Parch)\n",
    "\n",
    "df_imputed['text'] = df_imputed.apply(get_text,axis=1)\n",
    "textstring = ['Perished','Survived', ]\n",
    "\n",
    "plotly.offline.iplot({\n",
    "    'data': [ # creates a list using a comprehension\n",
    "        Scatter(x=df_imputed.Pclass[df_imputed.Survived==val].values+np.random.rand(*df_imputed.SibSp[df_imputed.Survived==val].shape)/2,\n",
    "                y=df_imputed.Age[df_imputed.Survived==val],\n",
    "                text=df_imputed.text[df_imputed.Survived==val].values.astype(str),\n",
    "                marker=Marker(size=df_imputed[df_imputed.Survived==val].SibSp, sizemode='area', sizeref=0.01,),\n",
    "                mode='markers',\n",
    "                name=textstring[val]) for val in [0,1]\n",
    "    ],\n",
    "    'layout': Layout(xaxis=XAxis(title='Social Class'), \n",
    "                     yaxis=YAxis(title='Age'),\n",
    "                     title='Age and Class Scatter Plot, Size = number of siblings and spouses'),\n",
    "    \n",
    "}, show_link=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check more about using plotly here:\n",
    "- https://plot.ly/python/ipython-notebook-tutorial/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook you learned:**\n",
    "- How to read in from a file using pandas\n",
    "- How to manipulate data with basic operations in pandas\n",
    "- How to group data in pandas \n",
    "- How to use Scikit-learn and pandas for imputation\n",
    "- Some common visualizations in Pandas, Seaborn, and Plotly\n",
    "\n",
    "Want some additional practice?\n",
    "Try to create and use some Bokeh examples that are similar to the plots we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
